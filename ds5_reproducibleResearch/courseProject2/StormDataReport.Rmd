---
title: "Investigation into human and economic cost of various types of weather events, using the 'Storm Data' dataset"
author: "Tim F"
date: "22 November 2015"
output: html_document
---

## Synopsis
The following analysis uses the **Storm Data** dataset to investigate which types of weather events have shown the largest impact, in terms of both 
economic impact and impact to human health. The data cleaning process is demonstrated, in which only the most recent records are kept (a justification 
is given in the appendix). The cleaned data show that tornadoes are the most harmful in both respects, showing high rates of fatalities, injuries and property damage. However tornadoes are not the only significant source of harm identified in the dataset. 

## Data Processing
There should be a section titled Data Processing which describes (in words and code) how the data were loaded into R and processed for analysis. In particular, your analysis must start from the raw CSV file containing the data. You cannot do any preprocessing outside the document. If preprocessing is time-consuming you may consider using the cache = TRUE option for certain code chunks.

Dependencies for this analysis:
```{r}
library(dplyr)
library(ggplot2)
library(lubridate)
```

Lets download the storm data from the course website:
```{r cache=TRUE}
zippedFilename <- 'data/stormData.csv.bz2'
dir.create('data', showWarnings = FALSE)
download.file('https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2', destfile = zippedFilename)
stormData <- read.csv(zippedFilename)
stormData$BGN_DATE  <-  as.POSIXct(stormData$BGN_DATE, format = "%m/%d/%Y")
```

I've decided that it is most straight-forward to only use data from 2007 to present, as these data are much cleaner
than prior data. See the appendix for further justification of this.
```{r}
stormData <-filter(stormData, BGN_DATE >= ymd("2007-01-01"))
stormData <- droplevels(stormData)
```

For value of property and crop damage, values are stored as dollar-mulitplier pairs, which are stored in separate columns.
The mulitpliers are:
```{r}
unique(stormData$PROPDMGEXP)
```
where K = thousands, M = millions, B = billions and '0' corresponds to a single event where damages were recorded as zero.

Create a 'total.damages' column, where these multipliers have been applied, and crop and property damages have been combined.
```{r}
multiplyDamages <- function(value, multiplier){
  switch(as.character(multiplier),
    K = value * 1e3,
    M = value * 1e6,
    B = value * 1e9,
    '0' = value * 0
    )
}

stormData <- 
  stormData %>%
  rowwise() %>%
  mutate(total.damages = multiplyDamages(PROPDMG, PROPDMGEXP)
                       + multiplyDamages(CROPDMG, CROPDMGEXP))
```

Now the data are clean and in a convenient format, produce a summary table of the statistics of interest for each type of event. It is from this table we will draw our results.

In this table, compute the total damage, fatalities and injuries for each event type:
```{r}
impactSummary <- 
  stormData %>% 
  group_by(EVTYPE) %>% 
  summarise(total.damages = sum(total.damages), 
            Fatalities = sum(FATALITIES), 
            Injuries = sum(INJURIES)) %>%
  arrange(desc(total.damages))

head(impactSummary)
```

## Results
This section addresses the specific questions put forth for this assignment.

### Q1: Across the United States, which types of events (as indicated in the EVTYPE variable) are most harmful with respect to population health?
This question is answered by investigating total fatalities and injuries for each event type.

The following plot shows total fatalities for each event type over the selected period (from 2007 up to 2012):
```{r}
qplot(
  data = mutate(impactSummary, EVTYPE = reorder(EVTYPE, desc(Fatalities))), 
  x = EVTYPE, 
  y = Fatalities, 
  geom = 'bar', 
  stat = 'identity',
  main = 'Total number of fatalities aggregated over all event types, 2007-2012',
  xlab = 'Event Type',
  ylab = 'Number of fatalities'
) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```
This plot shows tornadoes to be by far the largest cause of fatalities in the present dataset. 

The dataset also provides figures for number of injuries for each event. The following plot shows the relationship between 
fatalities and injuries for the six event types with the highest fatality counts:
```{r}
qplot(
  data = impactSummary %>% arrange(desc(Fatalities)) %>% slice(1:6), 
  x = Fatalities, 
  y = Injuries, 
  shape = EVTYPE, 
  color = EVTYPE, size = I(5),
  main = 'Number of fatalities vs. number of injuries for six event\n types with highest fatality rates, 2007-2012',
  xlab = 'Number of fatalities',
  ylab = 'Number of injuries'
) + theme(legend.title=element_blank())
```
As the plot indicates, the relationship between injuries and fatalities is not strictly linear for these event types.
For instance, flash flooding has a relativly high fatality rate compared to injury rate, while lightning is the opposite.

Which event type can be said to have the worst effect on public health depends partly on the fatality/injury 'exchange rate',
or how much significance is placed on a single injury with respect to a single fatality. Determining this rate is outside of the scope
of this analysis. 

That said, it is clear to see that in the given dataset tornadoes have the greatest impact on public health, as they have contributed 
to far more injuries *and* fatalities than any othe type of event. 

For reference, here are the 5 largest causes of fatalities:
```{r}
impactSummary %>% 
  arrange(desc(Fatalities)) %>% 
  select(EVTYPE, Fatalities) %>% 
  slice(1:5)
```

And here are the 5 largest causes of injuries:
```{r}
impactSummary %>% 
  arrange(desc(Injuries)) %>% 
  select(EVTYPE, Injuries) %>% 
  slice(1:5)
```

### Q2: Across the United States, which types of events have the greatest economic consequences?
This question is answered by investigating the sum of all property and crop damages for each event type.

The following plot shows the total of all property and crop damages over the selected period (from 2007 up to 2012).
```{r}
qplot(
  data = mutate(impactSummary, EVTYPE = reorder(EVTYPE, desc(total.damages))), 
  x = EVTYPE, 
  y = total.damages, 
  geom = 'bar', 
  stat = 'identity',
  main = 'Total damages (dollars) aggregated over all event types, 2007-2012',
  xlab = 'Event Type',
  ylab = 'Total Damages (dollars)'
) + theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5))
```
From this we can see that a fairly small number of event types account for a large majority of total economic damages. For instance, the top three
event types show more aggregate damages than the rest of the event types combined:
```{r}
with(impactSummary, sum(total.damages[1:3]) > sum(total.damages[-(1:3)]))
```

These top three event types, which a responsible for the majority of economic damages for the events in the dataset, are shown below:
```{r}
impactSummary[1:3,c('EVTYPE', "total.damages")]
```


## Apendix

### Justification for subsetting from 2007 to present:
According to http://www.ncdc.noaa.gov/stormevents/details.jsp, only a limited number of event types were recorded
prior to 1996. Hence it seems that to avoid over-representing certain event types, only data from 1996 onward should
be used for this analysis.

Investigating further, and in light of the discussion presented in [The History of the Storm Events Database] (http://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/The-History-of-the-Storm-Events-Database.docx), I had a
look into how event codes have been assigned throughout the dataset. The aforementioned document 
states that the cleanest available data is from 2006 to the present. The following steps investigate this:

Here I create a function which, for a given year and dataset field, will tell me how many unique values 
there are for that field, from the given year to the present. Specifically I'm looking to see if there is
a proliferation of event codes as we head backwards in time.
```{r}
stormData <- read.csv(zippedFilename)
stormData$BGN_DATE  <-  as.POSIXct(stormData$BGN_DATE, format = "%m/%d/%Y")

categoriesSinceYear <- function(category, givenYear) {
  subsetSinceYear <- 
    stormData %>% 
    filter(BGN_DATE >= ymd(paste0(givenYear,"-01-01")))
  
  length(unique(subsetSinceYear[,category]))
  }
```

This function can then be used to look at how many unique event codes exist if we subset the data from a given year onwards:
```{r}
nEvtypes <- sapply(1996:2006, function(x) {categoriesSinceYear('EVTYPE', x)})
data.frame(year = 1990:2010, nEvtypes = nEvtypes)
```
From this you can see that if we include all data from 1990 to today, our dataset would have almost a thousand different event codes.
These codes are hard to make sense of, because of the potential for overlap and duplication (e.g. there are codes for both 'STRONG WIND' and 'HIGH WIND')
Keep in mind also that there are only 48 event types officially defined in [NWS Directive 10-1605](http://www.ncdc.noaa.gov/stormevents/pd01016005curr.pdf).

On the other hand, if we subset our data from 2006 onwards, we will have a much tidier `r nEvtypes[17]` different codes, or if we subset from 2007 we have the official number of 48 different events. 

In light of this, I've chosen to subset from 2007 onwards, with the justification that this leaves a much tidier dataset to work with. Note that this comes with limitations, for instance I am less likely to have accounted for more rare, high-impact weather events. Notably, hurricane Katrina is not included in the subset of data used for this analysis. 
